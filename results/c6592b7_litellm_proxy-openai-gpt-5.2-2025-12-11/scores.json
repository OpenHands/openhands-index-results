[
  {
    "benchmark": "swe-bench-multimodal",
    "score": 20.6,
    "metric": "accuracy",
    "cost_per_instance": 2.77,
    "average_runtime": 1571.0,
    "full_archive": "https://results.eval.all-hands.dev/eval-21320837315-gpt-5-2_litellm_proxy-openai-gpt-5-2-2025-12-11_26-01-25-04-55.tar.gz",
    "tags": [
      "swe-bench-multimodal"
    ]
  }
]
