[
  {
    "benchmark": "swe-bench-multimodal",
    "score": 28.4,
    "metric": "accuracy",
    "cost_per_instance": 2.37,
    "average_runtime": 602.0,
    "full_archive": "https://results.eval.all-hands.dev/swebenchmultimodal/litellm_proxy-anthropic-claude-opus-4-6/21767110679/results.tar.gz",
    "tags": [
      "swe-bench-multimodal"
    ],
    "agent_version": "v1.11.0",
    "submission_time": "2026-02-07T01:54:03+00:00"
  }
]
