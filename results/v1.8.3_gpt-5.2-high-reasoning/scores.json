[
  {
    "benchmark": "swe-bench",
    "score": 74.2,
    "metric": "accuracy",
    "cost_per_instance": 0.88,
    "average_runtime": 584.0,
    "full_archive": "https://storage.googleapis.com/openhands-evaluation-results/eval-21093149818-gpt-5-2-hi_litellm_proxy-openai-gpt-5-2-2025-12-11_26-01-17-16-06.tar.gz",
    "tags": [
      "swe-bench"
    ]
  }
]
